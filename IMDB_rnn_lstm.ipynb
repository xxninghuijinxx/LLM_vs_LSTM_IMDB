{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2570c8c-85cc-4f50-b683-8ec592889f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b00839-8d1f-43d9-9df3-07619d7f0fb5",
   "metadata": {},
   "source": [
    "###### 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd86405-2331-4f15-88e5-11a966cecde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a720c5-25cf-4578-8454-f05000f3a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['sentiment'].map({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ded4524-0495-4a05-8472-167834b12cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['review'].values\n",
    "labels = df['labels'].values\n",
    "text_train, text_test, label_train, label_test = train_test_split(texts, labels, test_size=0.3, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e9dc8-9fa5-40af-a04d-e800fe7407f9",
   "metadata": {},
   "source": [
    "###### 2. 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10df64d4-8e97-4af4-b1ae-399f7f374d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    #stop_word = set(nltk.corpus.stopwords.words('english'))\n",
    "    #tokens = [word for word in tokens if word not in stop_word]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b22ad3-bf96-4bbf-96d9-6f8715ab9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(iter_data):\n",
    "    for text in iter_data:\n",
    "        yield nltk_tokenizer(text)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(text_train), specials=['<unk>', '<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26b8924-a220-4bad-af3d-f5d5abfac8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "def text_pipeline(text):\n",
    "    tokens = nltk_tokenizer(text)\n",
    "    token_ids = vocab(tokens)\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [vocab['<pad>']] * (max_len - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_len]\n",
    "    return token_ids\n",
    "\n",
    "def label_pipeline(label):\n",
    "    return int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57250028-e991-4df4-893e-45d1592cc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(zip(text_train, label_train))\n",
    "test_dataset = list(zip(text_test, label_test))\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_dataset)\n",
    "test_dataset = to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4d3a24-6ac7-4942-8874-01c4ad74848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(batch):\n",
    "    text_list, label_list = [], []\n",
    "    for text, label in batch:\n",
    "        text_list.append(torch.tensor(text_pipeline(text), dtype = torch.int64))\n",
    "        label_list.append(torch.tensor(label_pipeline(label), dtype = torch.float32))\n",
    "    text_batch = torch.stack(text_list)\n",
    "    label_batch = torch.stack(label_list)\n",
    "    return text_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf4c57b-46a3-47f6-96bd-c3b89f0f61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_function)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1373f6a3-ae4e-416e-9e94-641b494dcb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "epoch = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da579cdb-1ff8-478e-a8dc-5fa28833da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_imdb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=vocab['<pad>'])\n",
    "        self.rnn_layer1 = nn.RNN(128, 64, batch_first=True, num_layers = 3)\n",
    "        self.linear = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, x = self.rnn_layer1(x)\n",
    "        #单层 设置前面的num_layers\n",
    "        #x = x.squeeze(0)\n",
    "        #多层\n",
    "        x = x[-1]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed2f298-5543-4921-bd77-eb35a4bf93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_imdb_multilayers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=vocab['<pad>'])\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=64,\n",
    "            num_layers=4,              # 多层加深表达能力\n",
    "            batch_first=True,\n",
    "            dropout=0.3                # dropout between LSTM layers\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # x: (batch, seq_len) → (batch, seq_len, emb_dim)\n",
    "        _, (h_n, _) = self.lstm(x)          # h_n: (num_layers, batch, hidden_size)\n",
    "        x = self.dropout(h_n[-1])           # 取最后一层的输出 → (batch, hidden_size)\n",
    "        x = self.linear(x)                  # → (batch, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3a0b97-49cf-4046-94d9-65f4651804a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_imdb = lstm_imdb_multilayers().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lstm_imdb.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d8cd5dd-0ae8-42be-92c9-29398faca91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6600\n",
      "Train Accuracy: 73.11%\n",
      "Epoch 2, Loss: 0.5216\n",
      "Train Accuracy: 82.43%\n",
      "Epoch 3, Loss: 0.4003\n",
      "Train Accuracy: 87.12%\n",
      "Epoch 4, Loss: 0.3050\n",
      "Train Accuracy: 91.13%\n",
      "Epoch 5, Loss: 0.2258\n",
      "Train Accuracy: 94.84%\n",
      "Epoch 6, Loss: 0.1624\n",
      "Train Accuracy: 96.92%\n",
      "Epoch 7, Loss: 0.1214\n",
      "Train Accuracy: 97.56%\n",
      "Epoch 8, Loss: 0.0828\n",
      "Train Accuracy: 98.78%\n",
      "Epoch 9, Loss: 0.0590\n",
      "Train Accuracy: 99.16%\n",
      "Epoch 10, Loss: 0.0511\n",
      "Train Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    lstm_imdb.train()\n",
    "    total_loss = 0\n",
    "    for text, label in train_loader:\n",
    "        text = text.to(device)\n",
    "        label = label.unsqueeze(1).to(device)\n",
    "        \n",
    "        outputs = lstm_imdb(text)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {i+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on training set\n",
    "    lstm_imdb.eval()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    with torch.no_grad():\n",
    "        for text, label in train_loader:\n",
    "            text = text.to(device)\n",
    "            label = label.unsqueeze(1).to(device)\n",
    "            outputs = lstm_imdb(text)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct_train += (preds == label).sum().item()\n",
    "            total_train += label.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb90fba2-fecc-42dd-9e63-1d45ff685b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练总耗时: 156.03 秒\n"
     ]
    }
   ],
   "source": [
    "print(f\"训练总耗时: {end_time - start_time:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e05c1d-1d3a-4fd1-892c-bc648d0cd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_imdb.state_dict(), 'lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea065406-dc5d-47c3-b72f-a244c9283458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.05%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_imdb.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        text = text.to(device)\n",
    "        label = label.unsqueeze(1).to(device)\n",
    "        outputs = lstm_imdb(text)\n",
    "        predictions = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (predictions.float() == label).sum().item()\n",
    "        total += label.size(0)\n",
    "print(f\"Test Accuracy: {correct / total * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79891d73-c706-406a-8ec9-3b6b6e937938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_full)",
   "language": "python",
   "name": "torch_full"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
